{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a14e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 📚 Imports principaux\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "# 📦 PyTorch Forecasting + Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# 📦 PyTorch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 📂 Gestion des chemins\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# === PATHS ===\n",
    "BASE_DIR = Path.cwd().parents[1]  # 🔥 remonte de 2 niveaux\n",
    "DATA_DIR = BASE_DIR / \"data\" / \"modified_data\"\n",
    "MODELS_DIR = BASE_DIR / \"models\" / \"tft\"\n",
    "\n",
    "# Créer le dossier modèle si besoin\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === GPU Check ===\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"✅ Using device: {DEVICE}\")\n",
    "\n",
    "# Optionnel : Style graphique propre\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e3451a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_train_val_dl_global(df: pd.DataFrame, val_size: float = 0.2):\n",
    "    \"\"\"\n",
    "    Split temporel global pour toutes les régions ensemble.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    \n",
    "    n_total = len(df[\"date\"].unique())\n",
    "    n_val = int(n_total * val_size)\n",
    "\n",
    "    date_val_start = df[\"date\"].unique()[-n_val]\n",
    "\n",
    "    df_train = df[df[\"date\"] < date_val_start].copy()\n",
    "    df_val = df[df[\"date\"] >= date_val_start].copy()\n",
    "\n",
    "    return df_train, df_val\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a6b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# === Paths ===\n",
    "BASE_DIR = Path.cwd().parents[1]\n",
    "DATA_DIR = BASE_DIR / \"data\" / \"modified_data\"\n",
    "\n",
    "# === Ajout du dossier data_processing pour pouvoir importer ===\n",
    "sys.path.append(str(BASE_DIR))\n",
    "\n",
    "# === Import fonctions ===\n",
    "from data_processing.transformation import transform_dl\n",
    "\n",
    "# === Paramètre fréquence (daily ou hourly) ===\n",
    "FREQ = \"daily\"\n",
    "\n",
    "# === Chargement et préparation des données ===\n",
    "\n",
    "# 1. Charger le train complet\n",
    "df_train = pd.read_csv(DATA_DIR / f\"train_{FREQ}.csv\")\n",
    "\n",
    "# 2. Appliquer la transformation spéciale Deep Learning\n",
    "df_train_transformed = transform_dl(df_train, filter_too_short=True)\n",
    "\n",
    "# 3. Split en train/val\n",
    "df_train_final, df_val_final = split_train_val_dl_global(df_train_transformed)\n",
    "\n",
    "# 4. Charger aussi le test pour plus tard\n",
    "df_test = pd.read_csv(DATA_DIR / f\"test_{FREQ}.csv\")\n",
    "df_test_final = transform_dl(df_test, filter_too_short=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dbc3651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>insee_region</th>\n",
       "      <th>conso_elec_mw</th>\n",
       "      <th>conso_gaz_mw</th>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>apparent_temperature_max</th>\n",
       "      <th>apparent_temperature_min</th>\n",
       "      <th>...</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>sunshine_duration</th>\n",
       "      <th>daylight_duration</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_gusts_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>shortwave_radiation_sum</th>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>11</td>\n",
       "      <td>389597.0</td>\n",
       "      <td>53348.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>8.7</td>\n",
       "      <td>61</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>35040</td>\n",
       "      <td>65040</td>\n",
       "      <td>24366.94</td>\n",
       "      <td>30049.78</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.6</td>\n",
       "      <td>248</td>\n",
       "      <td>3.55</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>27</td>\n",
       "      <td>108098.0</td>\n",
       "      <td>65331.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>55</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>35460</td>\n",
       "      <td>65220</td>\n",
       "      <td>24513.07</td>\n",
       "      <td>29719.84</td>\n",
       "      <td>27.1</td>\n",
       "      <td>53.6</td>\n",
       "      <td>261</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>28</td>\n",
       "      <td>152060.0</td>\n",
       "      <td>110271.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>55</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>34860</td>\n",
       "      <td>65400</td>\n",
       "      <td>25155.29</td>\n",
       "      <td>30508.68</td>\n",
       "      <td>25.5</td>\n",
       "      <td>49.3</td>\n",
       "      <td>246</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32</td>\n",
       "      <td>248073.0</td>\n",
       "      <td>165424.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>53</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>34020</td>\n",
       "      <td>64800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30781.38</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>213</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>44</td>\n",
       "      <td>214344.0</td>\n",
       "      <td>161462.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>53</td>\n",
       "      <td>4.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>33660</td>\n",
       "      <td>63840</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30193.14</td>\n",
       "      <td>19.3</td>\n",
       "      <td>43.6</td>\n",
       "      <td>206</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date insee_region  conso_elec_mw  conso_gaz_mw  temperature_2m_max  \\\n",
       "0 2013-01-01           11       389597.0       53348.0                 8.7   \n",
       "1 2013-01-01           27       108098.0       65331.0                 9.0   \n",
       "2 2013-01-01           28       152060.0      110271.0                 8.9   \n",
       "3 2013-01-01           32       248073.0      165424.0                 8.0   \n",
       "4 2013-01-01           44       214344.0      161462.0                 7.1   \n",
       "\n",
       "   temperature_2m_min  precipitation_sum  weather_code  \\\n",
       "0                 3.8                8.7            61   \n",
       "1                 4.4                6.4            55   \n",
       "2                 3.9                8.1            55   \n",
       "3                 3.7                8.0            53   \n",
       "4                 4.3                6.1            53   \n",
       "\n",
       "   apparent_temperature_max  apparent_temperature_min  ...  sunrise  sunset  \\\n",
       "0                       5.7                       0.3  ...    35040   65040   \n",
       "1                       6.1                       0.9  ...    35460   65220   \n",
       "2                       5.8                       0.6  ...    34860   65400   \n",
       "3                       5.4                       0.5  ...    34020   64800   \n",
       "4                       4.1                      -0.1  ...    33660   63840   \n",
       "\n",
       "   sunshine_duration  daylight_duration  wind_speed_10m_max  \\\n",
       "0           24366.94           30049.78                25.0   \n",
       "1           24513.07           29719.84                27.1   \n",
       "2           25155.29           30508.68                25.5   \n",
       "3               0.00           30781.38                25.0   \n",
       "4               0.00           30193.14                19.3   \n",
       "\n",
       "   wind_gusts_10m_max  wind_direction_10m_dominant  shortwave_radiation_sum  \\\n",
       "0                48.6                          248                     3.55   \n",
       "1                53.6                          261                     3.87   \n",
       "2                49.3                          246                     3.82   \n",
       "3                50.0                          213                     0.96   \n",
       "4                43.6                          206                     0.91   \n",
       "\n",
       "   et0_fao_evapotranspiration  time_idx  \n",
       "0                        0.59         0  \n",
       "1                        0.52         0  \n",
       "2                        0.52         0  \n",
       "3                        0.61         0  \n",
       "4                        0.62         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e0b5397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                           0\n",
       "insee_region                   0\n",
       "conso_elec_mw                  0\n",
       "conso_gaz_mw                   0\n",
       "temperature_2m_max             0\n",
       "temperature_2m_min             0\n",
       "precipitation_sum              0\n",
       "weather_code                   0\n",
       "apparent_temperature_max       0\n",
       "apparent_temperature_min       0\n",
       "rain_sum                       0\n",
       "snowfall_sum                   0\n",
       "precipitation_hours            0\n",
       "sunrise                        0\n",
       "sunset                         0\n",
       "sunshine_duration              0\n",
       "daylight_duration              0\n",
       "wind_speed_10m_max             0\n",
       "wind_gusts_10m_max             0\n",
       "wind_direction_10m_dominant    0\n",
       "shortwave_radiation_sum        0\n",
       "et0_fao_evapotranspiration     0\n",
       "time_idx                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430534a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31776, 23)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce58f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "insee_region\n",
       "11    2648\n",
       "27    2648\n",
       "28    2648\n",
       "32    2648\n",
       "44    2648\n",
       "52    2648\n",
       "75    2648\n",
       "53    2648\n",
       "76    2648\n",
       "84    2648\n",
       "93    2648\n",
       "24    2648\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final[\"insee_region\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c59edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "insee_region\n",
       "75    662\n",
       "53    662\n",
       "28    662\n",
       "76    662\n",
       "84    662\n",
       "93    662\n",
       "44    662\n",
       "32    661\n",
       "24    661\n",
       "11    661\n",
       "27    661\n",
       "52    661\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_final[\"insee_region\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40df2288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ df_train_final info:\n",
      "date                           0\n",
      "insee_region                   0\n",
      "conso_elec_mw                  0\n",
      "conso_gaz_mw                   0\n",
      "temperature_2m_max             0\n",
      "temperature_2m_min             0\n",
      "precipitation_sum              0\n",
      "weather_code                   0\n",
      "apparent_temperature_max       0\n",
      "apparent_temperature_min       0\n",
      "rain_sum                       0\n",
      "snowfall_sum                   0\n",
      "precipitation_hours            0\n",
      "sunrise                        0\n",
      "sunset                         0\n",
      "sunshine_duration              0\n",
      "daylight_duration              0\n",
      "wind_speed_10m_max             0\n",
      "wind_gusts_10m_max             0\n",
      "wind_direction_10m_dominant    0\n",
      "shortwave_radiation_sum        0\n",
      "et0_fao_evapotranspiration     0\n",
      "time_idx                       0\n",
      "dtype: int64\n",
      "\n",
      "✅ df_val_final info:\n",
      "date                           0\n",
      "insee_region                   0\n",
      "conso_elec_mw                  0\n",
      "conso_gaz_mw                   0\n",
      "temperature_2m_max             0\n",
      "temperature_2m_min             0\n",
      "precipitation_sum              0\n",
      "weather_code                   0\n",
      "apparent_temperature_max       0\n",
      "apparent_temperature_min       0\n",
      "rain_sum                       0\n",
      "snowfall_sum                   0\n",
      "precipitation_hours            0\n",
      "sunrise                        0\n",
      "sunset                         0\n",
      "sunshine_duration              0\n",
      "daylight_duration              0\n",
      "wind_speed_10m_max             0\n",
      "wind_gusts_10m_max             0\n",
      "wind_direction_10m_dominant    0\n",
      "shortwave_radiation_sum        0\n",
      "et0_fao_evapotranspiration     0\n",
      "time_idx                       0\n",
      "dtype: int64\n",
      "\n",
      "=== Vérification lignes avec NaN dans train ===\n",
      "Empty DataFrame\n",
      "Columns: [date, insee_region, conso_elec_mw, conso_gaz_mw, temperature_2m_max, temperature_2m_min, precipitation_sum, weather_code, apparent_temperature_max, apparent_temperature_min, rain_sum, snowfall_sum, precipitation_hours, sunrise, sunset, sunshine_duration, daylight_duration, wind_speed_10m_max, wind_gusts_10m_max, wind_direction_10m_dominant, shortwave_radiation_sum, et0_fao_evapotranspiration, time_idx]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n",
      "\n",
      "=== Vérification lignes avec NaN dans val ===\n",
      "Empty DataFrame\n",
      "Columns: [date, insee_region, conso_elec_mw, conso_gaz_mw, temperature_2m_max, temperature_2m_min, precipitation_sum, weather_code, apparent_temperature_max, apparent_temperature_min, rain_sum, snowfall_sum, precipitation_hours, sunrise, sunset, sunshine_duration, daylight_duration, wind_speed_10m_max, wind_gusts_10m_max, wind_direction_10m_dominant, shortwave_radiation_sum, et0_fao_evapotranspiration, time_idx]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# === Vérification NaN/None après transformation ===\n",
    "print(\"✅ df_train_final info:\")\n",
    "print(df_train_final.isnull().sum())\n",
    "print(\"\\n✅ df_val_final info:\")\n",
    "print(df_val_final.isnull().sum())\n",
    "\n",
    "# Optionnel: Afficher lignes problématiques si NaN trouvés\n",
    "print(\"\\n=== Vérification lignes avec NaN dans train ===\")\n",
    "print(df_train_final[df_train_final.isnull().any(axis=1)])\n",
    "\n",
    "print(\"\\n=== Vérification lignes avec NaN dans val ===\")\n",
    "print(df_val_final[df_val_final.isnull().any(axis=1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3db6097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Points par région dans le train :\n",
      "insee_region\n",
      "11    2648\n",
      "27    2648\n",
      "28    2648\n",
      "32    2648\n",
      "44    2648\n",
      "52    2648\n",
      "75    2648\n",
      "53    2648\n",
      "76    2648\n",
      "84    2648\n",
      "93    2648\n",
      "24    2648\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✅ Points par région dans la val :\n",
      "insee_region\n",
      "75    662\n",
      "53    662\n",
      "28    662\n",
      "76    662\n",
      "84    662\n",
      "93    662\n",
      "44    662\n",
      "32    661\n",
      "24    661\n",
      "11    661\n",
      "27    661\n",
      "52    661\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Points par région dans le train :\")\n",
    "print(df_train_final[\"insee_region\"].value_counts())\n",
    "\n",
    "print(\"\\n✅ Points par région dans la val :\")\n",
    "print(df_val_final[\"insee_region\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8ac180f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Types des colonnes dans train :\n",
      "date                           datetime64[ns]\n",
      "insee_region                           object\n",
      "conso_elec_mw                         float64\n",
      "conso_gaz_mw                          float64\n",
      "temperature_2m_max                    float64\n",
      "temperature_2m_min                    float64\n",
      "precipitation_sum                     float64\n",
      "weather_code                            int64\n",
      "apparent_temperature_max              float64\n",
      "apparent_temperature_min              float64\n",
      "rain_sum                              float64\n",
      "snowfall_sum                          float64\n",
      "precipitation_hours                   float64\n",
      "sunrise                                 int32\n",
      "sunset                                  int32\n",
      "sunshine_duration                     float64\n",
      "daylight_duration                     float64\n",
      "wind_speed_10m_max                    float64\n",
      "wind_gusts_10m_max                    float64\n",
      "wind_direction_10m_dominant             int64\n",
      "shortwave_radiation_sum               float64\n",
      "et0_fao_evapotranspiration            float64\n",
      "time_idx                                int32\n",
      "dtype: object\n",
      "\n",
      "✅ Types des colonnes dans val :\n",
      "date                           datetime64[ns]\n",
      "insee_region                           object\n",
      "conso_elec_mw                         float64\n",
      "conso_gaz_mw                          float64\n",
      "temperature_2m_max                    float64\n",
      "temperature_2m_min                    float64\n",
      "precipitation_sum                     float64\n",
      "weather_code                            int64\n",
      "apparent_temperature_max              float64\n",
      "apparent_temperature_min              float64\n",
      "rain_sum                              float64\n",
      "snowfall_sum                          float64\n",
      "precipitation_hours                   float64\n",
      "sunrise                                 int32\n",
      "sunset                                  int32\n",
      "sunshine_duration                     float64\n",
      "daylight_duration                     float64\n",
      "wind_speed_10m_max                    float64\n",
      "wind_gusts_10m_max                    float64\n",
      "wind_direction_10m_dominant             int64\n",
      "shortwave_radiation_sum               float64\n",
      "et0_fao_evapotranspiration            float64\n",
      "time_idx                                int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "for col in df_train_final.columns:\n",
    "    if df_train_final[col].isnull().any():\n",
    "        print(f\"❗ Attention : NaN dans colonne '{col}'\")\n",
    "\n",
    "for col in df_val_final.columns:\n",
    "    if df_val_final[col].isnull().any():\n",
    "        print(f\"❗ Attention : NaN dans colonne '{col}'\")\n",
    "\n",
    "# Vérifions aussi les types au cas où\n",
    "print(\"\\n✅ Types des colonnes dans train :\")\n",
    "print(df_train_final.dtypes)\n",
    "\n",
    "print(\"\\n✅ Types des colonnes dans val :\")\n",
    "print(df_val_final.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceb16b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train samples: 31500\n",
      "✅ Val samples: 7663\n",
      "✅ x keys: ['x_cat', 'x_cont', 'encoder_length', 'decoder_length', 'encoder_target', 'encoder_time_idx_start', 'groups', 'target_scale']\n",
      "✅ y type: <class 'tuple'>\n",
      "✅ y[0] length: 2\n",
      "✅ y[1]: None\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from pytorch_forecasting.data.encoders import MultiNormalizer, TorchNormalizer\n",
    "\n",
    "# === Définir paramètres ===\n",
    "MAX_ENCODER_LENGTH = 24    # Nombre d'heures passées utilisées\n",
    "MAX_PREDICTION_LENGTH = 24 # Nombre d'heures à prédire\n",
    "\n",
    "# === Définir les variables ===\n",
    "target_cols = [\"conso_elec_mw\", \"conso_gaz_mw\"]\n",
    "time_idx = \"time_idx\"      # Colonne pour l'ordre temporel\n",
    "group_id = \"insee_region\"  # Pour identifier une série temporelle unique\n",
    "\n",
    "target_normalizer = MultiNormalizer(\n",
    "    [TorchNormalizer()] * len(target_cols)  # un normalizer par target\n",
    ")\n",
    "\n",
    "# === Créer TimeSeriesDataSet pour le TRAIN ===\n",
    "training = TimeSeriesDataSet(\n",
    "    df_train_final,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=[\"conso_elec_mw\", \"conso_gaz_mw\"],\n",
    "    group_ids=[\"insee_region\"],\n",
    "    max_encoder_length=24,\n",
    "    max_prediction_length=24,\n",
    "    min_encoder_length=12,            # 👈 Autoriser des séquences plus courtes\n",
    "    min_prediction_idx=1,             # 👈 Autoriser à prédire même à partir d'un point\n",
    "    time_varying_known_reals=[\n",
    "        \"temperature_2m_max\", \"temperature_2m_min\", \"precipitation_sum\", \"weather_code\", \"apparent_temperature_max\",\n",
    "        \"apparent_temperature_min\", \"rain_sum\", \"snowfall_sum\", \"precipitation_hours\", \"sunrise\", \"sunset\",\n",
    "        \"sunshine_duration\", \"daylight_duration\", \"wind_speed_10m_max\", \"wind_gusts_10m_max\",\n",
    "        \"wind_direction_10m_dominant\", \"shortwave_radiation_sum\", \"et0_fao_evapotranspiration\"\n",
    "    ],\n",
    "    time_varying_unknown_reals=[\"conso_elec_mw\", \"conso_gaz_mw\"],\n",
    "    static_categoricals=[\"insee_region\"],\n",
    "    target_normalizer=target_normalizer,\n",
    "    allow_missing_timesteps=True,\n",
    ")\n",
    "\n",
    "# === TimeSeriesDataSet pour la VALIDATION ===\n",
    "validation = TimeSeriesDataSet.from_dataset(training, df_val_final)\n",
    "\n",
    "# === DEBUG Prints ===\n",
    "print(f\"✅ Train samples: {len(training)}\")\n",
    "print(f\"✅ Val samples: {len(validation)}\")\n",
    "\n",
    "# Optionnel : tester un sample\n",
    "sample = training[0]\n",
    "x, y = sample\n",
    "\n",
    "print(f\"✅ x keys: {list(x.keys())}\")\n",
    "print(f\"✅ y type: {type(y)}\")\n",
    "\n",
    "# Afficher la “shape” ou la longueur de chaque élément de y\n",
    "if isinstance(y, tuple):\n",
    "    for i, yi in enumerate(y):\n",
    "        if hasattr(yi, \"shape\"):\n",
    "            print(f\"✅ y[{i}] shape: {tuple(yi.shape)}\")\n",
    "        elif hasattr(yi, \"__len__\"):\n",
    "            print(f\"✅ y[{i}] length: {len(yi)}\")\n",
    "        else:\n",
    "            print(f\"✅ y[{i}]: {yi}\")\n",
    "else:\n",
    "    # cas inattendu : y n’est pas un tuple\n",
    "    print(f\"✅ y shape: {getattr(y, 'shape', None)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff852e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# à la place de `from pytorch_forecasting.data import TemporalDataLoader`\n",
    "# et de la construction manuelle de DataLoader :\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataloader = training.to_dataloader(\n",
    "    train=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2deb849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de paramètres du modèle : 139.1k paramètres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "# === Définir le modèle TFT ===\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=1e-3,\n",
    "    hidden_size=32,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=16,\n",
    "    loss=QuantileLoss(quantiles=[0.1, 0.5, 0.9]),  # c’est ici qu’on précise les quantiles\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "print(f\"Nombre de paramètres du modèle : {tft.size()/1e3:.1f}k paramètres\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69f8f5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\arnov\\Desktop\\Energy-prediction\\model\\DeepLearning\\checkpoints\\tft exists and is not empty.\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | MultiLoss                       | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 72     | train\n",
      "3  | prescalers                         | ModuleDict                      | 672    | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 2.0 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 44.9 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 39.7 K | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 2.6 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | ModuleList                      | 198    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "139 K     Trainable params\n",
      "0         Non-trainable params\n",
      "139 K     Total params\n",
      "0.556     Total estimated model params size (MB)\n",
      "735       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 246/246 [01:07<00:00,  3.63it/s, v_num=7, train_loss_step=7.76e+3, val_loss=1.12e+4, train_loss_epoch=7.85e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 246/246 [01:07<00:00,  3.62it/s, v_num=7, train_loss_step=7.76e+3, val_loss=1.12e+4, train_loss_epoch=7.85e+3]\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# === Callbacks ===\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # ou \"val_quantile_loss\" selon ce que vous logguez\n",
    "    patience=7,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints/tft\",\n",
    "    filename=\"best_tft\",\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    ")\n",
    "\n",
    "# === Trainer ===\n",
    "trainer = Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1,\n",
    "    callbacks=[early_stop, checkpoint],\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=1.0,\n",
    "    limit_val_batches=1.0,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "# === Lancement de l'entraînement ===\n",
    "trainer.fit(\n",
    "    tft,                    # votre TemporalFusionTransformer\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd035a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Meilleur modèle TFT chargé depuis : C:\\Users\\arnov\\Desktop\\Energy-prediction\\model\\DeepLearning\\checkpoints\\tft\\best_tft-v1.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "print(f\" Meilleur modèle TFT chargé depuis : {best_model_path}\")\n",
    "\n",
    "# 2. Charger le modèle depuis le checkpoint\n",
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abfdc272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Remonter au dossier racine\n",
    "BASE_DIR = Path(__file__).resolve().parents[2] if \"__file__\" in globals() else Path.cwd().parents[1]\n",
    "DATA_DIR = BASE_DIR / \"data\" / \"modified_data\"\n",
    "\n",
    "# Charger le fichier test\n",
    "df_test = pd.read_csv(DATA_DIR / \"test_daily.csv\")\n",
    "df_test[\"date\"] = pd.to_datetime(df_test[\"date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d6d9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.transformation import transform_dl\n",
    "\n",
    "df_test_transformed = transform_dl(df_test, filter_too_short=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47c63ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TimeSeriesDataSet.from_dataset(\n",
    "    training,                      # your original training TimeSeriesDataSet\n",
    "    df_test_transformed,           # the DataFrame you preprocessed with transform_dl()\n",
    "    predict=True,                  # prepare it for prediction\n",
    "    stop_randomization=True        # turn off any shuffling/augmentation\n",
    ")\n",
    "\n",
    "# 2) Create a DataLoader (no shuffling)\n",
    "test_dataloader = test_dataset.to_dataloader(\n",
    "    train=False,\n",
    "    batch_size=64,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c92a53d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m tft \u001b[38;5;241m=\u001b[39m TemporalFusionTransformer\u001b[38;5;241m.\u001b[39mload_from_checkpoint(best_model_path)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# produce raw predictions and the input batch x\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m raw_predictions, x \u001b[38;5;241m=\u001b[39m tft\u001b[38;5;241m.\u001b[39mpredict(test_dataloader, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# visualize one example\u001b[39;00m\n\u001b[0;32m     11\u001b[0m tft\u001b[38;5;241m.\u001b[39mplot_prediction(x, raw_predictions, idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "\n",
    "# load the best model you trained\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path  \n",
    "tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# produce raw predictions and the input batch x\n",
    "raw_predictions, x = tft.predict(test_dataloader, mode=\"raw\", return_x=True)\n",
    "\n",
    "# visualize one example\n",
    "tft.plot_prediction(x, raw_predictions, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97715957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
