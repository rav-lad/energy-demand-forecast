{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a14e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# üìö Imports principaux\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "# üì¶ PyTorch Forecasting + Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# üì¶ PyTorch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# üìÇ Gestion des chemins\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# === PATHS ===\n",
    "BASE_DIR = Path.cwd().parents[1]  # üî• remonte de 2 niveaux\n",
    "DATA_DIR = BASE_DIR / \"data\" / \"modified_data\"\n",
    "MODELS_DIR = BASE_DIR / \"models\" / \"tft\"\n",
    "\n",
    "# Cr√©er le dossier mod√®le si besoin\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === GPU Check ===\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"‚úÖ Using device: {DEVICE}\")\n",
    "\n",
    "# Optionnel : Style graphique propre\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e3451a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_train_val_dl_global(df: pd.DataFrame, val_size: float = 0.2):\n",
    "    \"\"\"\n",
    "    Split temporel global pour toutes les r√©gions ensemble.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    \n",
    "    n_total = len(df[\"date\"].unique())\n",
    "    n_val = int(n_total * val_size)\n",
    "\n",
    "    date_val_start = df[\"date\"].unique()[-n_val]\n",
    "\n",
    "    df_train = df[df[\"date\"] < date_val_start].copy()\n",
    "    df_val = df[df[\"date\"] >= date_val_start].copy()\n",
    "\n",
    "    return df_train, df_val\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a6b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# === Paths ===\n",
    "BASE_DIR = Path.cwd().parents[1]\n",
    "DATA_DIR = BASE_DIR / \"data\" / \"modified_data\"\n",
    "\n",
    "# === Ajout du dossier data_processing pour pouvoir importer ===\n",
    "sys.path.append(str(BASE_DIR))\n",
    "\n",
    "# === Import fonctions ===\n",
    "from data_processing.transformation import transform_dl\n",
    "\n",
    "# === Param√®tre fr√©quence (daily ou hourly) ===\n",
    "FREQ = \"daily\"\n",
    "\n",
    "# === Chargement et pr√©paration des donn√©es ===\n",
    "\n",
    "# 1. Charger le train complet\n",
    "df_train = pd.read_csv(DATA_DIR / f\"train_{FREQ}.csv\")\n",
    "\n",
    "# 2. Appliquer la transformation sp√©ciale Deep Learning\n",
    "df_train_transformed = transform_dl(df_train, filter_too_short=True)\n",
    "\n",
    "# 3. Split en train/val\n",
    "df_train_final, df_val_final = split_train_val_dl_global(df_train_transformed)\n",
    "\n",
    "# 4. Charger aussi le test pour plus tard\n",
    "df_test = pd.read_csv(DATA_DIR / f\"test_{FREQ}.csv\")\n",
    "df_test_final = transform_dl(df_test, filter_too_short=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dbc3651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>insee_region</th>\n",
       "      <th>conso_elec_mw</th>\n",
       "      <th>conso_gaz_mw</th>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>apparent_temperature_max</th>\n",
       "      <th>apparent_temperature_min</th>\n",
       "      <th>...</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>sunshine_duration</th>\n",
       "      <th>daylight_duration</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_gusts_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>shortwave_radiation_sum</th>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>11</td>\n",
       "      <td>389597.0</td>\n",
       "      <td>53348.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>8.7</td>\n",
       "      <td>61</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>35040</td>\n",
       "      <td>65040</td>\n",
       "      <td>24366.94</td>\n",
       "      <td>30049.78</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.6</td>\n",
       "      <td>248</td>\n",
       "      <td>3.55</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>27</td>\n",
       "      <td>108098.0</td>\n",
       "      <td>65331.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>55</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>35460</td>\n",
       "      <td>65220</td>\n",
       "      <td>24513.07</td>\n",
       "      <td>29719.84</td>\n",
       "      <td>27.1</td>\n",
       "      <td>53.6</td>\n",
       "      <td>261</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>28</td>\n",
       "      <td>152060.0</td>\n",
       "      <td>110271.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>55</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>34860</td>\n",
       "      <td>65400</td>\n",
       "      <td>25155.29</td>\n",
       "      <td>30508.68</td>\n",
       "      <td>25.5</td>\n",
       "      <td>49.3</td>\n",
       "      <td>246</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32</td>\n",
       "      <td>248073.0</td>\n",
       "      <td>165424.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>53</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>34020</td>\n",
       "      <td>64800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30781.38</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>213</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>44</td>\n",
       "      <td>214344.0</td>\n",
       "      <td>161462.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>53</td>\n",
       "      <td>4.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>33660</td>\n",
       "      <td>63840</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30193.14</td>\n",
       "      <td>19.3</td>\n",
       "      <td>43.6</td>\n",
       "      <td>206</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date insee_region  conso_elec_mw  conso_gaz_mw  temperature_2m_max  \\\n",
       "0 2013-01-01           11       389597.0       53348.0                 8.7   \n",
       "1 2013-01-01           27       108098.0       65331.0                 9.0   \n",
       "2 2013-01-01           28       152060.0      110271.0                 8.9   \n",
       "3 2013-01-01           32       248073.0      165424.0                 8.0   \n",
       "4 2013-01-01           44       214344.0      161462.0                 7.1   \n",
       "\n",
       "   temperature_2m_min  precipitation_sum  weather_code  \\\n",
       "0                 3.8                8.7            61   \n",
       "1                 4.4                6.4            55   \n",
       "2                 3.9                8.1            55   \n",
       "3                 3.7                8.0            53   \n",
       "4                 4.3                6.1            53   \n",
       "\n",
       "   apparent_temperature_max  apparent_temperature_min  ...  sunrise  sunset  \\\n",
       "0                       5.7                       0.3  ...    35040   65040   \n",
       "1                       6.1                       0.9  ...    35460   65220   \n",
       "2                       5.8                       0.6  ...    34860   65400   \n",
       "3                       5.4                       0.5  ...    34020   64800   \n",
       "4                       4.1                      -0.1  ...    33660   63840   \n",
       "\n",
       "   sunshine_duration  daylight_duration  wind_speed_10m_max  \\\n",
       "0           24366.94           30049.78                25.0   \n",
       "1           24513.07           29719.84                27.1   \n",
       "2           25155.29           30508.68                25.5   \n",
       "3               0.00           30781.38                25.0   \n",
       "4               0.00           30193.14                19.3   \n",
       "\n",
       "   wind_gusts_10m_max  wind_direction_10m_dominant  shortwave_radiation_sum  \\\n",
       "0                48.6                          248                     3.55   \n",
       "1                53.6                          261                     3.87   \n",
       "2                49.3                          246                     3.82   \n",
       "3                50.0                          213                     0.96   \n",
       "4                43.6                          206                     0.91   \n",
       "\n",
       "   et0_fao_evapotranspiration  time_idx  \n",
       "0                        0.59         0  \n",
       "1                        0.52         0  \n",
       "2                        0.52         0  \n",
       "3                        0.61         0  \n",
       "4                        0.62         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e0b5397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                           0\n",
       "insee_region                   0\n",
       "conso_elec_mw                  0\n",
       "conso_gaz_mw                   0\n",
       "temperature_2m_max             0\n",
       "temperature_2m_min             0\n",
       "precipitation_sum              0\n",
       "weather_code                   0\n",
       "apparent_temperature_max       0\n",
       "apparent_temperature_min       0\n",
       "rain_sum                       0\n",
       "snowfall_sum                   0\n",
       "precipitation_hours            0\n",
       "sunrise                        0\n",
       "sunset                         0\n",
       "sunshine_duration              0\n",
       "daylight_duration              0\n",
       "wind_speed_10m_max             0\n",
       "wind_gusts_10m_max             0\n",
       "wind_direction_10m_dominant    0\n",
       "shortwave_radiation_sum        0\n",
       "et0_fao_evapotranspiration     0\n",
       "time_idx                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430534a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31776, 23)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce58f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "insee_region\n",
       "11    2648\n",
       "27    2648\n",
       "28    2648\n",
       "32    2648\n",
       "44    2648\n",
       "52    2648\n",
       "75    2648\n",
       "53    2648\n",
       "76    2648\n",
       "84    2648\n",
       "93    2648\n",
       "24    2648\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final[\"insee_region\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c59edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "insee_region\n",
       "75    662\n",
       "53    662\n",
       "28    662\n",
       "76    662\n",
       "84    662\n",
       "93    662\n",
       "44    662\n",
       "32    661\n",
       "24    661\n",
       "11    661\n",
       "27    661\n",
       "52    661\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_final[\"insee_region\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40df2288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ df_train_final info:\n",
      "date                           0\n",
      "insee_region                   0\n",
      "conso_elec_mw                  0\n",
      "conso_gaz_mw                   0\n",
      "temperature_2m_max             0\n",
      "temperature_2m_min             0\n",
      "precipitation_sum              0\n",
      "weather_code                   0\n",
      "apparent_temperature_max       0\n",
      "apparent_temperature_min       0\n",
      "rain_sum                       0\n",
      "snowfall_sum                   0\n",
      "precipitation_hours            0\n",
      "sunrise                        0\n",
      "sunset                         0\n",
      "sunshine_duration              0\n",
      "daylight_duration              0\n",
      "wind_speed_10m_max             0\n",
      "wind_gusts_10m_max             0\n",
      "wind_direction_10m_dominant    0\n",
      "shortwave_radiation_sum        0\n",
      "et0_fao_evapotranspiration     0\n",
      "time_idx                       0\n",
      "dtype: int64\n",
      "\n",
      "‚úÖ df_val_final info:\n",
      "date                           0\n",
      "insee_region                   0\n",
      "conso_elec_mw                  0\n",
      "conso_gaz_mw                   0\n",
      "temperature_2m_max             0\n",
      "temperature_2m_min             0\n",
      "precipitation_sum              0\n",
      "weather_code                   0\n",
      "apparent_temperature_max       0\n",
      "apparent_temperature_min       0\n",
      "rain_sum                       0\n",
      "snowfall_sum                   0\n",
      "precipitation_hours            0\n",
      "sunrise                        0\n",
      "sunset                         0\n",
      "sunshine_duration              0\n",
      "daylight_duration              0\n",
      "wind_speed_10m_max             0\n",
      "wind_gusts_10m_max             0\n",
      "wind_direction_10m_dominant    0\n",
      "shortwave_radiation_sum        0\n",
      "et0_fao_evapotranspiration     0\n",
      "time_idx                       0\n",
      "dtype: int64\n",
      "\n",
      "=== V√©rification lignes avec NaN dans train ===\n",
      "Empty DataFrame\n",
      "Columns: [date, insee_region, conso_elec_mw, conso_gaz_mw, temperature_2m_max, temperature_2m_min, precipitation_sum, weather_code, apparent_temperature_max, apparent_temperature_min, rain_sum, snowfall_sum, precipitation_hours, sunrise, sunset, sunshine_duration, daylight_duration, wind_speed_10m_max, wind_gusts_10m_max, wind_direction_10m_dominant, shortwave_radiation_sum, et0_fao_evapotranspiration, time_idx]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n",
      "\n",
      "=== V√©rification lignes avec NaN dans val ===\n",
      "Empty DataFrame\n",
      "Columns: [date, insee_region, conso_elec_mw, conso_gaz_mw, temperature_2m_max, temperature_2m_min, precipitation_sum, weather_code, apparent_temperature_max, apparent_temperature_min, rain_sum, snowfall_sum, precipitation_hours, sunrise, sunset, sunshine_duration, daylight_duration, wind_speed_10m_max, wind_gusts_10m_max, wind_direction_10m_dominant, shortwave_radiation_sum, et0_fao_evapotranspiration, time_idx]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# === V√©rification NaN/None apr√®s transformation ===\n",
    "print(\"‚úÖ df_train_final info:\")\n",
    "print(df_train_final.isnull().sum())\n",
    "print(\"\\n‚úÖ df_val_final info:\")\n",
    "print(df_val_final.isnull().sum())\n",
    "\n",
    "# Optionnel: Afficher lignes probl√©matiques si NaN trouv√©s\n",
    "print(\"\\n=== V√©rification lignes avec NaN dans train ===\")\n",
    "print(df_train_final[df_train_final.isnull().any(axis=1)])\n",
    "\n",
    "print(\"\\n=== V√©rification lignes avec NaN dans val ===\")\n",
    "print(df_val_final[df_val_final.isnull().any(axis=1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3db6097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Points par r√©gion dans le train :\n",
      "insee_region\n",
      "11    2648\n",
      "27    2648\n",
      "28    2648\n",
      "32    2648\n",
      "44    2648\n",
      "52    2648\n",
      "75    2648\n",
      "53    2648\n",
      "76    2648\n",
      "84    2648\n",
      "93    2648\n",
      "24    2648\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ Points par r√©gion dans la val :\n",
      "insee_region\n",
      "75    662\n",
      "53    662\n",
      "28    662\n",
      "76    662\n",
      "84    662\n",
      "93    662\n",
      "44    662\n",
      "32    661\n",
      "24    661\n",
      "11    661\n",
      "27    661\n",
      "52    661\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Points par r√©gion dans le train :\")\n",
    "print(df_train_final[\"insee_region\"].value_counts())\n",
    "\n",
    "print(\"\\n‚úÖ Points par r√©gion dans la val :\")\n",
    "print(df_val_final[\"insee_region\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8ac180f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Types des colonnes dans train :\n",
      "date                           datetime64[ns]\n",
      "insee_region                           object\n",
      "conso_elec_mw                         float64\n",
      "conso_gaz_mw                          float64\n",
      "temperature_2m_max                    float64\n",
      "temperature_2m_min                    float64\n",
      "precipitation_sum                     float64\n",
      "weather_code                            int64\n",
      "apparent_temperature_max              float64\n",
      "apparent_temperature_min              float64\n",
      "rain_sum                              float64\n",
      "snowfall_sum                          float64\n",
      "precipitation_hours                   float64\n",
      "sunrise                                 int32\n",
      "sunset                                  int32\n",
      "sunshine_duration                     float64\n",
      "daylight_duration                     float64\n",
      "wind_speed_10m_max                    float64\n",
      "wind_gusts_10m_max                    float64\n",
      "wind_direction_10m_dominant             int64\n",
      "shortwave_radiation_sum               float64\n",
      "et0_fao_evapotranspiration            float64\n",
      "time_idx                                int32\n",
      "dtype: object\n",
      "\n",
      "‚úÖ Types des colonnes dans val :\n",
      "date                           datetime64[ns]\n",
      "insee_region                           object\n",
      "conso_elec_mw                         float64\n",
      "conso_gaz_mw                          float64\n",
      "temperature_2m_max                    float64\n",
      "temperature_2m_min                    float64\n",
      "precipitation_sum                     float64\n",
      "weather_code                            int64\n",
      "apparent_temperature_max              float64\n",
      "apparent_temperature_min              float64\n",
      "rain_sum                              float64\n",
      "snowfall_sum                          float64\n",
      "precipitation_hours                   float64\n",
      "sunrise                                 int32\n",
      "sunset                                  int32\n",
      "sunshine_duration                     float64\n",
      "daylight_duration                     float64\n",
      "wind_speed_10m_max                    float64\n",
      "wind_gusts_10m_max                    float64\n",
      "wind_direction_10m_dominant             int64\n",
      "shortwave_radiation_sum               float64\n",
      "et0_fao_evapotranspiration            float64\n",
      "time_idx                                int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "for col in df_train_final.columns:\n",
    "    if df_train_final[col].isnull().any():\n",
    "        print(f\"‚ùó Attention : NaN dans colonne '{col}'\")\n",
    "\n",
    "for col in df_val_final.columns:\n",
    "    if df_val_final[col].isnull().any():\n",
    "        print(f\"‚ùó Attention : NaN dans colonne '{col}'\")\n",
    "\n",
    "# V√©rifions aussi les types au cas o√π\n",
    "print(\"\\n‚úÖ Types des colonnes dans train :\")\n",
    "print(df_train_final.dtypes)\n",
    "\n",
    "print(\"\\n‚úÖ Types des colonnes dans val :\")\n",
    "print(df_val_final.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceb16b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train samples: 31500\n",
      "‚úÖ Val samples: 7663\n",
      "‚úÖ x keys: ['x_cat', 'x_cont', 'encoder_length', 'decoder_length', 'encoder_target', 'encoder_time_idx_start', 'groups', 'target_scale']\n",
      "‚úÖ y type: <class 'tuple'>\n",
      "‚úÖ y[0] length: 2\n",
      "‚úÖ y[1]: None\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from pytorch_forecasting.data.encoders import MultiNormalizer, TorchNormalizer\n",
    "\n",
    "# === D√©finir param√®tres ===\n",
    "MAX_ENCODER_LENGTH = 24    # Nombre d'heures pass√©es utilis√©es\n",
    "MAX_PREDICTION_LENGTH = 24 # Nombre d'heures √† pr√©dire\n",
    "\n",
    "# === D√©finir les variables ===\n",
    "target_cols = [\"conso_elec_mw\", \"conso_gaz_mw\"]\n",
    "time_idx = \"time_idx\"      # Colonne pour l'ordre temporel\n",
    "group_id = \"insee_region\"  # Pour identifier une s√©rie temporelle unique\n",
    "\n",
    "target_normalizer = MultiNormalizer(\n",
    "    [TorchNormalizer()] * len(target_cols)  # un normalizer par target\n",
    ")\n",
    "\n",
    "# === Cr√©er TimeSeriesDataSet pour le TRAIN ===\n",
    "training = TimeSeriesDataSet(\n",
    "    df_train_final,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=[\"conso_elec_mw\", \"conso_gaz_mw\"],\n",
    "    group_ids=[\"insee_region\"],\n",
    "    max_encoder_length=24,\n",
    "    max_prediction_length=24,\n",
    "    min_encoder_length=12,            # üëà Autoriser des s√©quences plus courtes\n",
    "    min_prediction_idx=1,             # üëà Autoriser √† pr√©dire m√™me √† partir d'un point\n",
    "    time_varying_known_reals=[\n",
    "        \"temperature_2m_max\", \"temperature_2m_min\", \"precipitation_sum\", \"weather_code\", \"apparent_temperature_max\",\n",
    "        \"apparent_temperature_min\", \"rain_sum\", \"snowfall_sum\", \"precipitation_hours\", \"sunrise\", \"sunset\",\n",
    "        \"sunshine_duration\", \"daylight_duration\", \"wind_speed_10m_max\", \"wind_gusts_10m_max\",\n",
    "        \"wind_direction_10m_dominant\", \"shortwave_radiation_sum\", \"et0_fao_evapotranspiration\"\n",
    "    ],\n",
    "    time_varying_unknown_reals=[\"conso_elec_mw\", \"conso_gaz_mw\"],\n",
    "    static_categoricals=[\"insee_region\"],\n",
    "    target_normalizer=target_normalizer,\n",
    "    allow_missing_timesteps=True,\n",
    ")\n",
    "\n",
    "# === TimeSeriesDataSet pour la VALIDATION ===\n",
    "validation = TimeSeriesDataSet.from_dataset(training, df_val_final)\n",
    "\n",
    "# === DEBUG Prints ===\n",
    "print(f\"‚úÖ Train samples: {len(training)}\")\n",
    "print(f\"‚úÖ Val samples: {len(validation)}\")\n",
    "\n",
    "# Optionnel : tester un sample\n",
    "sample = training[0]\n",
    "x, y = sample\n",
    "\n",
    "print(f\"‚úÖ x keys: {list(x.keys())}\")\n",
    "print(f\"‚úÖ y type: {type(y)}\")\n",
    "\n",
    "# Afficher la ‚Äúshape‚Äù ou la longueur de chaque √©l√©ment de y\n",
    "if isinstance(y, tuple):\n",
    "    for i, yi in enumerate(y):\n",
    "        if hasattr(yi, \"shape\"):\n",
    "            print(f\"‚úÖ y[{i}] shape: {tuple(yi.shape)}\")\n",
    "        elif hasattr(yi, \"__len__\"):\n",
    "            print(f\"‚úÖ y[{i}] length: {len(yi)}\")\n",
    "        else:\n",
    "            print(f\"‚úÖ y[{i}]: {yi}\")\n",
    "else:\n",
    "    # cas inattendu : y n‚Äôest pas un tuple\n",
    "    print(f\"‚úÖ y shape: {getattr(y, 'shape', None)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff852e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √† la place de `from pytorch_forecasting.data import TemporalDataLoader`\n",
    "# et de la construction manuelle de DataLoader :\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataloader = training.to_dataloader(\n",
    "    train=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2deb849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de param√®tres du mod√®le : 139.1k param√®tres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "# === D√©finir le mod√®le TFT ===\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=1e-3,\n",
    "    hidden_size=32,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=16,\n",
    "    loss=QuantileLoss(quantiles=[0.1, 0.5, 0.9]),  # c‚Äôest ici qu‚Äôon pr√©cise les quantiles\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "print(f\"Nombre de param√®tres du mod√®le : {tft.size()/1e3:.1f}k param√®tres\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69f8f5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\arnov\\Desktop\\Energy-prediction\\model\\DeepLearning\\checkpoints\\tft exists and is not empty.\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | MultiLoss                       | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 72     | train\n",
      "3  | prescalers                         | ModuleDict                      | 672    | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 2.0 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 44.9 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 39.7 K | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 2.6 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | ModuleList                      | 198    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "139 K     Trainable params\n",
      "0         Non-trainable params\n",
      "139 K     Total params\n",
      "0.556     Total estimated model params size (MB)\n",
      "735       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 246/246 [01:07<00:00,  3.63it/s, v_num=7, train_loss_step=7.76e+3, val_loss=1.12e+4, train_loss_epoch=7.85e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 246/246 [01:07<00:00,  3.62it/s, v_num=7, train_loss_step=7.76e+3, val_loss=1.12e+4, train_loss_epoch=7.85e+3]\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# === Callbacks ===\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # ou \"val_quantile_loss\" selon ce que vous logguez\n",
    "    patience=7,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints/tft\",\n",
    "    filename=\"best_tft\",\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    ")\n",
    "\n",
    "# === Trainer ===\n",
    "trainer = Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1,\n",
    "    callbacks=[early_stop, checkpoint],\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=1.0,\n",
    "    limit_val_batches=1.0,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "# === Lancement de l'entra√Ænement ===\n",
    "trainer.fit(\n",
    "    tft,                    # votre TemporalFusionTransformer\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd035a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Meilleur mod√®le TFT charg√© depuis : C:\\Users\\arnov\\Desktop\\Energy-prediction\\model\\DeepLearning\\checkpoints\\tft\\best_tft-v1.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "print(f\" Meilleur mod√®le TFT charg√© depuis : {best_model_path}\")\n",
    "\n",
    "# 2. Charger le mod√®le depuis le checkpoint\n",
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abfdc272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Remonter au dossier racine\n",
    "BASE_DIR = Path(__file__).resolve().parents[2] if \"__file__\" in globals() else Path.cwd().parents[1]\n",
    "DATA_DIR = BASE_DIR / \"data\" / \"modified_data\"\n",
    "\n",
    "# Charger le fichier test\n",
    "df_test = pd.read_csv(DATA_DIR / \"test_daily.csv\")\n",
    "df_test[\"date\"] = pd.to_datetime(df_test[\"date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d6d9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.transformation import transform_dl\n",
    "\n",
    "df_test_transformed = transform_dl(df_test, filter_too_short=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47c63ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TimeSeriesDataSet.from_dataset(\n",
    "    training,                      # your original training TimeSeriesDataSet\n",
    "    df_test_transformed,           # the DataFrame you preprocessed with transform_dl()\n",
    "    predict=True,                  # prepare it for prediction\n",
    "    stop_randomization=True        # turn off any shuffling/augmentation\n",
    ")\n",
    "\n",
    "# 2) Create a DataLoader (no shuffling)\n",
    "test_dataloader = test_dataset.to_dataloader(\n",
    "    train=False,\n",
    "    batch_size=64,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c92a53d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\arnov\\anaconda3\\envs\\ML_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m tft \u001b[38;5;241m=\u001b[39m TemporalFusionTransformer\u001b[38;5;241m.\u001b[39mload_from_checkpoint(best_model_path)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# produce raw predictions and the input batch x\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m raw_predictions, x \u001b[38;5;241m=\u001b[39m tft\u001b[38;5;241m.\u001b[39mpredict(test_dataloader, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# visualize one example\u001b[39;00m\n\u001b[0;32m     11\u001b[0m tft\u001b[38;5;241m.\u001b[39mplot_prediction(x, raw_predictions, idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "\n",
    "# load the best model you trained\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path  \n",
    "tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# produce raw predictions and the input batch x\n",
    "raw_predictions, x = tft.predict(test_dataloader, mode=\"raw\", return_x=True)\n",
    "\n",
    "# visualize one example\n",
    "tft.plot_prediction(x, raw_predictions, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97715957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
